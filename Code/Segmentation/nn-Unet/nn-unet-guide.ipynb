{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch torchvision torchaudio\n!pip install torch --upgrade\n!pip install triton\n!pip install nnunetv2","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare the data for the nnunetV2","metadata":{}},{"cell_type":"markdown","source":"### The following cell only if the mapping is different or the labels have decimals (e.g: 1.00002 instead of 1)\n### This sometime happen in generated data or data with noise so we standardize the labels mapping","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\nimport nibabel as nib\nimport numpy as np\n\n# === User Input Required: Define Paths ===\n# Please update these paths to your dataset directories\n\n# Input directory containing NIfTI label files\ninput_dir = \"/path/to/input/labels\"  # e.g., \"./cycle_generated_nifti/labels\"\n\n# Output directory to save processed labels\noutput_dir = \"/path/to/output/processed_labels\"  # e.g., \"./processed_labels\"\n\n# Create output directory if it does not exist\nos.makedirs(output_dir, exist_ok=True)\n\n# === Define mapping dictionary ===\n# Maps original intensity values to desired class labels\n\nvalue_map = {\n    #replace the first columns with your actual labels if they are not standardized to (0,1,2,3,4)\n    0: 0,\n    20: 1,\n    60: 2,\n    100: 3,\n    140: 4\n}\n\n# === Process each label file ===\nfor file in os.listdir(input_dir):\n    if file.endswith(\".nii\"):\n        file_path = os.path.join(input_dir, file)\n        \n        # Load NIfTI file\n        nifti_img = nib.load(file_path)\n        data = nifti_img.get_fdata()\n        \n        # Initialize mapped data with zeros (int32 type)\n        mapped_data = np.zeros_like(data, dtype=np.int32)\n        \n        # Tolerance for floating point matching (in intensity units)\n        tolerance = 5\n        \n        for old_val, new_val in value_map.items():\n            mask = np.abs(data - old_val) < tolerance\n            mapped_data[mask] = new_val\n        \n        # Create new NIfTI image with mapped integer classes\n        new_nifti = nib.Nifti1Image(mapped_data, affine=nifti_img.affine, header=nifti_img.header)\n        \n        # Ensure data is saved as integers in NIfTI\n        new_nifti.set_data_dtype(np.int32)\n        \n        # Save to output directory with the same name\n        output_path = os.path.join(output_dir, file)\n        nib.save(new_nifti, output_path)\n        \n        print(f\"Processed and saved {file}\")\n\nprint(f\"âœ… All labels processed with correct integer classes and saved in {output_dir}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### The following cells are the mandatory nnunetV2 preparation with the required structure (must be run)","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\n\n# === User Input Required: Define Paths ===\n# Please update these paths to your dataset directories\n\n# Root directory for nnU-Net raw dataset\nnnunet_raw = \"/path/to/nnUNet_raw/DatasetXXX_YOURDATASET\"  # e.g., \"./nnUNet_raw/Dataset033_EMIDEC\"\nos.makedirs(nnunet_raw, exist_ok=True)\n\n# Original dataset directories\nimage_train_dir = \"/path/to/original/images_train\"  # e.g., \"./nifti/images_train\"\nimage_test_dir = \"/path/to/original/images_test\"    # e.g., \"./nifti/images_test\"\nmask_train_dir = \"/path/to/original/masks_train\"    # e.g., \"./nifti/masks_train\"\nmask_test_dir = \"/path/to/original/masks_test\"      # e.g., \"./nifti/masks_test\"\n\n# Generated dataset directories (e.g., after CycleGAN or preprocessing)\ngenerated_image_train_dir = \"/path/to/generated/images\"  # e.g., \"./cycle_generated_nifti/images\"\ngenerated_mask_train_dir = \"/path/to/generated/masks\"    # e.g., \"./processed_labels\"\n\n# === Define nnU-Net subdirectories ===\nnnunet_imagesTr = os.path.join(nnunet_raw, \"imagesTr\")\nnnunet_labelsTr = os.path.join(nnunet_raw, \"labelsTr\")\nnnunet_imagesTs = os.path.join(nnunet_raw, \"imagesTs\")\n\n# === Create required directories ===\nos.makedirs(nnunet_imagesTr, exist_ok=True)\nos.makedirs(nnunet_labelsTr, exist_ok=True)\nos.makedirs(nnunet_imagesTs, exist_ok=True)\n\nprint(\"âœ… nnU-Net dataset directories created successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Imports ===\nimport shutil\nimport glob\nimport os\n\n# === User Input Required: Define Paths ===\n# Please ensure these variables are defined prior to running this script:\n# - image_train_dir\n# - mask_train_dir\n# - generated_image_train_dir\n# - generated_mask_train_dir\n# - image_test_dir\n# - nnunet_imagesTr\n# - nnunet_labelsTr\n# - nnunet_imagesTs\n\n# Example:\n# image_train_dir = \"/path/to/images_train\"\n# mask_train_dir = \"/path/to/masks_train\"\n# generated_image_train_dir = \"/path/to/generated/images\"\n# generated_mask_train_dir = \"/path/to/generated/masks\"\n# image_test_dir = \"/path/to/images_test\"\n# nnunet_imagesTr = \"/path/to/nnUNet_raw/DatasetXXX/imagesTr\"\n# nnunet_labelsTr = \"/path/to/nnUNet_raw/DatasetXXX/labelsTr\"\n# nnunet_imagesTs = \"/path/to/nnUNet_raw/DatasetXXX/imagesTs\"\n\n# === Function to copy and rename files as .nii.gz ===\ndef copy_and_rename(src_dir, dest_dir):\n    for file in glob.glob(os.path.join(src_dir, \"*.nii\")):\n        case_name = os.path.basename(file).replace(\".nii\", \".nii.gz\")\n        shutil.copy(file, os.path.join(dest_dir, case_name))\n\n# === Copy original training images ===\ncopy_and_rename(image_train_dir, nnunet_imagesTr)\n\n# === Copy original training masks ===\ncopy_and_rename(mask_train_dir, nnunet_labelsTr)\n\n# === Copy generated training images ===\ncopy_and_rename(generated_image_train_dir, nnunet_imagesTr)\n\n# === Copy generated training masks ===\ncopy_and_rename(generated_mask_train_dir, nnunet_labelsTr)\n\n# === Copy test images (no labels) ===\ncopy_and_rename(image_test_dir, nnunet_imagesTs)\n\nprint(\"âœ… All data (original + generated) moved and renamed successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\ndataset_json = {\n    \"name\": \"EMIDEC\",\n    \"channel_names\": {\n        \"0\": \"CMR\"  # You can change this name to match your data modality\n    },\n    \"description\": \"Cardiac MRI dataset for nnU-Net\",\n    \"tensorImageSize\": \"3D\",\n    \"reference\": \"EMIDEC Challenge\",\n    \"licence\": \"CC-BY-SA 4.0\",\n    \"release\": \"1.0\",\n    \"modality\": {\"0\": \"CMR\"},\n    \"labels\": {\n        \"background\": 0,\n        \"Cavity\": 1,\n        \"Normal Myocardium\": 2,\n        \"Infarction\": 3,\n        \"No-Reflow\": 4\n    },\n    \"numTraining\": len(os.listdir(nnunet_imagesTr)),\n    \"file_ending\": \".nii.gz\"\n}\n\n# Save JSON file\njson_path = os.path.join(nnunet_raw, \"dataset.json\")\nwith open(json_path, \"w\") as f:\n    json.dump(dataset_json, f, indent=4)\n\nprint(\"Dataset JSON created successfully!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Training images:\", len(os.listdir(nnunet_imagesTr)))\nprint(\"Training masks:\", len(os.listdir(nnunet_labelsTr)))\nprint(\"Test images:\", len(os.listdir(nnunet_imagesTs)))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Set environment variables for nnU-Net\nos.environ['nnUNet_raw'] = '/kaggle/working/nnUNet_raw'\nos.environ['nnUNet_preprocessed'] = '/kaggle/working/nnUNet_preprocessed'\nos.environ['nnUNet_results'] = '/kaggle/working/nnUNet_results'\n\n# Verify if the environment variables are set correctly\nprint(\"nnUNet_raw:\", os.environ['nnUNet_raw'])\nprint(\"nnUNet_preprocessed:\", os.environ['nnUNet_preprocessed'])\nprint(\"nnUNet_results:\", os.environ['nnUNet_results'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Imports ===\nimport os\n\n# === Function to rename files in a given directory ===\ndef rename_files(data_dir):\n    # List all files in the directory\n    files = os.listdir(data_dir)\n\n    # Group files by case identifier (e.g., P036, P056, etc.)\n    case_dict = {}\n    for file in files:\n        case_id = file.split('.')[0]  # Extract the case identifier (e.g., 'P036' from 'P036.nii.gz')\n        if case_id not in case_dict:\n            case_dict[case_id] = []\n        case_dict[case_id].append(file)\n\n    # Rename the files in each group\n    for case_id, case_files in case_dict.items():\n        for i, file in enumerate(sorted(case_files)):  # Sort files to ensure correct order\n            new_name = f\"{case_id}_{i:04d}.nii.gz\"  # Format: 'Case_0000.nii.gz'\n            old_path = os.path.join(data_dir, file)\n            new_path = os.path.join(data_dir, new_name)\n            os.rename(old_path, new_path)\n            print(f\"Renamed {file} to {new_name}\")\n\n# === User Input Required: Define Directories ===\n# Please update these paths to your dataset directories\n\nimages_dir = '/path/to/nnUNet_raw/DatasetXXX/imagesTr'   # e.g., \"./nnUNet_raw/Dataset033_EMIDEC/imagesTr\"\nlabels_dir = '/path/to/nnUNet_raw/DatasetXXX/labelsTr'   # e.g., \"./nnUNet_raw/Dataset033_EMIDEC/labelsTr\"\n\n# === Rename files in both the images and labels directories ===\nrename_files(images_dir)\n# rename_files(labels_dir)  # Uncomment if you want to rename labels as well\n\nprint(\"âœ… File renaming completed.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Set environment variables for nnU-Net\nos.environ['nnUNet_raw'] = '/kaggle/working/nnUNet_raw'\nos.environ['nnUNet_preprocessed'] = '/kaggle/working/nnUNet_preprocessed'\nos.environ['nnUNet_results'] = '/kaggle/working/nnUNet_results'\n\n# Verify if the environment variables are set correctly\nprint(\"nnUNet_raw:\", os.environ['nnUNet_raw'])\nprint(\"nnUNet_preprocessed:\", os.environ['nnUNet_preprocessed'])\nprint(\"nnUNet_results:\", os.environ['nnUNet_results'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nnUNetv2_plan_and_preprocess -d 033 --verify_dataset_integrity\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train with the defualt loss and trainer\n### To apply a custom loss and trainer skip this part","metadata":{}},{"cell_type":"code","source":"!nnUNetv2_train 033 2d 0  #replace 033 with your actual dataset number\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### To run inference you need to rename the testing images too to case_0000","metadata":{}},{"cell_type":"code","source":"def rename_files(data_dir):\n    # List all the files in the directory\n    files = os.listdir(data_dir)\n\n    # Group files by case identifier (e.g., P036, P056, etc.)\n    case_dict = {}\n    for file in files:\n        case_id = file.split('.')[0]  # Get the case identifier (e.g., 'P036' from 'P036.nii.gz')\n        if case_id not in case_dict:\n            case_dict[case_id] = []\n        case_dict[case_id].append(file)\n\n    # Now rename the files in each group\n    for case_id, case_files in case_dict.items():\n        for i, file in enumerate(sorted(case_files)):  # Sorting the files by name ensures correct order\n            new_name = f\"{case_id}_{i:04d}.nii.gz\"  # Format the new name as 'Case_0000'\n            old_path = os.path.join(data_dir, file)\n            new_path = os.path.join(data_dir, new_name)\n            os.rename(old_path, new_path)\n            print(f\"Renamed {file} to {new_name}\")\n\ntest_dir = '/path/to/nnUNet_raw/DatasetXXX/imagesTs'\n\n# Rename files in both the images and labels directories\nrename_files(test_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\n\n# Define the base directory\nbase_dir = \"/path/to/nnUNet_results/Dataset033_EMIDEC/nnUNetTrainer__nnUNetPlans__2d/\"\n\n# Create the directory if it doesn't exist\nos.makedirs(base_dir, exist_ok=True)\n\n# Define the plan.json content\nplan_json = {\n    \"dataset_name\": \"Dataset033_EMIDEC\",\n    \"plans_name\": \"nnUNetPlans\",\n    \"original_median_spacing_after_transp\": [1.0, 1.0, 1.0],\n    \"original_median_shape_after_transp\": [7, 128, 128],\n    \"image_reader_writer\": \"SimpleITKIO\",\n    \"transpose_forward\": [0, 1, 2],\n    \"transpose_backward\": [0, 1, 2],\n    \"configurations\": {\n        \"2d\": {\n            \"data_identifier\": \"nnUNetPlans_2d\",\n            \"preprocessor_name\": \"DefaultPreprocessor\",\n            \"batch_size\": 30,\n            \"patch_size\": [128, 128],\n            \"median_image_size_in_voxels\": [128.0, 128.0],\n            \"spacing\": [1.0, 1.0],\n            \"normalization_schemes\": [\"ZScoreNormalization\"],\n            \"use_mask_for_norm\": [False],\n            \"resampling_fn_data\": \"resample_data_or_seg_to_shape\",\n            \"resampling_fn_seg\": \"resample_data_or_seg_to_shape\",\n            \"resampling_fn_data_kwargs\": {\"is_seg\": False, \"order\": 3, \"order_z\": 0, \"force_separate_z\": None},\n            \"resampling_fn_seg_kwargs\": {\"is_seg\": True, \"order\": 1, \"order_z\": 0, \"force_separate_z\": None},\n            \"resampling_fn_probabilities\": \"resample_data_or_seg_to_shape\",\n            \"resampling_fn_probabilities_kwargs\": {\"is_seg\": False, \"order\": 1, \"order_z\": 0, \"force_separate_z\": None},\n            \"architecture\": {\n                \"network_class_name\": \"dynamic_network_architectures.architectures.unet.PlainConvUNet\",\n                \"arch_kwargs\": {\n                    \"n_stages\": 6,\n                    \"features_per_stage\": [32, 64, 128, 256, 512, 512],\n                    \"conv_op\": \"torch.nn.modules.conv.Conv2d\",\n                    \"kernel_sizes\": [[3, 3]] * 6,\n                    \"strides\": [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]],\n                    \"n_conv_per_stage\": [2] * 6,\n                    \"n_conv_per_stage_decoder\": [2] * 5,\n                    \"conv_bias\": True,\n                    \"norm_op\": \"torch.nn.modules.instancenorm.InstanceNorm2d\",\n                    \"norm_op_kwargs\": {\"eps\": 1e-05, \"affine\": True},\n                    \"dropout_op\": None,\n                    \"dropout_op_kwargs\": None,\n                    \"nonlin\": \"torch.nn.LeakyReLU\",\n                    \"nonlin_kwargs\": {\"inplace\": True},\n                },\n                \"_kw_requires_import\": [\"conv_op\", \"norm_op\", \"dropout_op\", \"nonlin\"],\n            },\n            \"batch_dice\": True,\n        }\n    },\n    \"experiment_planner_used\": \"ExperimentPlanner\",\n    \"label_manager\": \"LabelManager\",\n    \"foreground_intensity_properties_per_channel\": {\n        \"0\": {\n            \"max\": 3093.0,\n            \"mean\": 2396.349853515625,\n            \"median\": 2377.0,\n            \"min\": 1806.0,\n            \"percentile_00_5\": 1882.0,\n            \"percentile_99_5\": 3093.0,\n            \"std\": 244.4371795654297,\n        }\n    },\n}\n\n# Define the dataset.json content\ndataset_json = {\n    \"name\": \"EMIDEC\",\n    \"channel_names\": {\"0\": \"CMR\"},\n    \"description\": \"Cardiac MRI dataset for nnU-Net\",\n    \"tensorImageSize\": \"3D\",\n    \"reference\": \"EMIDEC Challenge\",\n    \"licence\": \"CC-BY-SA 4.0\",\n    \"release\": \"1.0\",\n    \"modality\": {\"0\": \"CMR\"},\n    \"labels\": {\"background\": 0, \"Cavity\": 1, \"Normal Myocardium\": 2, \"Infarction\": 3, \"No-Reflow\": 4},\n    \"numTraining\": 85,\n    \"file_ending\": \".nii.gz\",\n}\n\n# Write the files\nwith open(os.path.join(base_dir, \"plans.json\"), \"w\") as f:\n    json.dump(plan_json, f, indent=4)\n\nwith open(os.path.join(base_dir, \"dataset.json\"), \"w\") as f:\n    json.dump(dataset_json, f, indent=4)\n\nprint(\"âœ… Directory and required files created successfully!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === nnU-Net v2 Inference Command ===\n# Please update the paths below to your own directories and checkpoint\n\n!nnUNetv2_predict \\\n    -i /path/to/nnUNet_raw/DatasetXXX/imagesTs \\  # Path to imagesTs directory inside your nnUNet dataset\n    -o /path/to/nnUNet_predictions/test_predictions \\  # Output directory for predictions\n    -d XXX \\  # Dataset number (e.g., 033)\n    -c 2d \\  # Trainer configuration (e.g., '2d' or '3d_fullres')\n    -f 0 \\  # Fold number used for inference (e.g., 0)\n    -chk /path/to/model_checkpoint/checkpoint_latest.pth  # Path to model checkpoint (.pth file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train with custom loss and trainer (example distance weighted but the same method applied for any other custom loss or trainer)","metadata":{}},{"cell_type":"code","source":"import os\n\n# Define the new loss file path\n# === User Input Required: Define Custom Loss File Path ===\n# Please replace this path with the actual path to your nnU-Net v2 library installation\n# For example, in Colab or your local environment, run:\n# import nnunetv2; print(nnunetv2.__file__) to locate the base package path\ncustom_loss_path = \"/path/to/nnunetv2/training/nnUNetTrainer/variants/loss/CustomDistanceLoss.py\"\n\ncustom_loss_code = \"\"\"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass CustomDistanceLoss(nn.Module):\n    def __init__(self, class_weights=None):\n        super(CustomDistanceLoss, self).__init__()\n        self.class_weights = torch.tensor(class_weights, dtype=torch.float32) if class_weights else None\n\n    def forward(self, prediction, target):\n        # Ensure we have lists of tensors for multi-scale outputs\n        if not isinstance(prediction, list):\n            prediction = [prediction]\n        if not isinstance(target, list):\n            target = [target]\n\n        num_classes = prediction[0].shape[1]\n        total_loss = 0.0\n        smooth = 1e-6\n\n        for i, (pred, tgt) in enumerate(zip(prediction, target)):\n            pred = pred.to(dtype=torch.float32, device=tgt.device)\n            tgt = tgt.to(dtype=torch.long, device=pred.device)\n\n            # Convert target to one-hot\n            targets_onehot = F.one_hot(tgt.squeeze(1), num_classes).permute(0, 3, 1, 2).float()\n\n            # ----- DISTANCE LOSS -----\n            # Compute squared difference between prediction and target\n            squared_difference = (pred - targets_onehot) ** 2\n            distance_loss = torch.mean(squared_difference, dim=(2, 3))\n\n            if self.class_weights is not None:\n                self.class_weights = self.class_weights.to(pred.device)  # Move to the same device\n                distance_loss = distance_loss * self.class_weights.view(1, num_classes)  # Apply weights\n            distance_loss = distance_loss.mean()\n\n            total_loss += distance_loss\n\n        return total_loss / len(prediction)\n\"\"\"\n\n# Write the loss code to the file\nwith open(custom_loss_path, \"w\") as f:\n    f.write(custom_loss_code)\n\nprint(\"âœ… CustomDistanceLoss.py has been created successfully!\")\n\n# Verify\nwith open(custom_loss_path, \"r\") as f:\n    print(f.read())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === User Input Required: Define Trainer File Path ===\n# Please replace this path with the actual path to your nnUNet v2 library installation.\n# You can find it by running:\n# import nnunetv2\n# print(nnunetv2.__file__)\n\ntrainer_path = \"/path/to/nnunetv2/training/nnUNetTrainer/variants/nnUNetTrainer_CustomDistance.py\"\n\ntrainer_code = \"\"\"import torch\nfrom nnunetv2.training.nnUNetTrainer.nnUNetTrainer import nnUNetTrainer\nfrom nnunetv2.training.nnUNetTrainer.variants.loss.CustomDistanceLoss import CustomDistanceLoss\n\nclass nnUNetTrainer_CustomDistance(nnUNetTrainer):\n    def _build_loss(self):\n        # Define class weights for loss function\n        class_weights = [0.0020701, 0.01770402, 0.0211376, 0.12820969, 1.0]\n        # class_weights = [0.1, 0.2, 0.3, 1.2820969, 1.5]\n        return CustomDistanceLoss(class_weights=class_weights)\n\"\"\"\n\n# Write the trainer code to the file\nwith open(trainer_path, \"w\") as f:\n    f.write(trainer_code)\n\nprint(\"âœ… nnUNetTrainer_CustomDistance.py has been created successfully!\")\n\n# Verify\nwith open(trainer_path, \"r\") as f:\n    print(f.read())\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nnUNetv2_train 033 2d 0 -tr nnUNetTrainer_CustomDistance  #replace 033 with your actual dataset number\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### To run inference using the custom trainer do this","metadata":{}},{"cell_type":"code","source":"test_dir = '/path/to/nnUNet_raw/DatasetXXX/imagesTs'\n\n# Rename files in both the images and labels directories\nrename_files(test_dir)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === nnU-Net v2 Inference Command with Custom Trainer ===\n# Please update the paths below to match your environment and dataset.\n\n!nnUNetv2_predict \\\n    -i /path/to/nnUNet_raw/DatasetXXX/imagesTs \\  # Path to imagesTs directory inside your nnUNet dataset\n    -o /path/to/nnUNet_predictions \\  # Output directory for predictions\n    -d XXX \\  # Dataset number (e.g., 033)\n    -c 2d \\  # Trainer configuration (e.g., '2d' or '3d_fullres')\n    -f 0 \\  # Fold number used for inference (e.g., 0)\n    -tr nnUNetTrainer_CustomDistance \\  # Name of your custom trainer class\n    -chk /path/to/model_checkpoint/checkpoint_best.pth  # Path to model checkpoint (.pth file)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualise Predictions","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\n\n# === User Input Required: Define Data Directory ===\n# Please update this path to your imagesTs directory\n\ndata_dir = '/path/to/nnUNet_raw/DatasetXXX/imagesTs'  # e.g., \"./nnUNet_raw/Dataset033_EMIDEC/imagesTs\"\n\n# === Rename .nii.gz files back to .nii ===\nfor file in os.listdir(data_dir):\n    if file.endswith(\".nii.gz\"):\n        old_path = os.path.join(data_dir, file)\n        new_name = file.replace(\".nii.gz\", \".nii\")\n        new_path = os.path.join(data_dir, new_name)\n        os.rename(old_path, new_path)\n        print(f\"âœ… Renamed {file} back to {new_name}\")\n\nprint(\"ðŸŽ¯ All files renamed back to .nii\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Imports ===\nimport nibabel as nib\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# === User Input Required: Define Instance ID and Paths ===\ninstance_file = \"YOUR_INSTANCE_ID\"  # e.g., \"P050\"\n\n# Define file paths below based on your directory structure\n\ninput_img_path = f\"/path/to/nnUNet_raw/DatasetXXX/imagesTs/{instance_file}_0000.nii\"  # e.g., \"./nnUNet_raw/Dataset033_EMIDEC/imagesTs/P050_0000.nii\"\ngt_path = f\"/path/to/ground_truth/masks_test/{instance_file}.nii\"  # e.g., \"./nifti/masks_test/P050.nii\"\npred_path = f\"/path/to/nnUNet_predictions/test_predictions/{instance_file}.nii.gz\"  # e.g., \"./nnUNet_predictions/test_predictions/P050.nii.gz\"\n\n# === Load data ===\ninput_img = nib.load(input_img_path).get_fdata()\ngt_mask = nib.load(gt_path).get_fdata()\npred_mask = nib.load(pred_path).get_fdata()\n\n# === Function to get middle slice if 3D ===\ndef get_middle_slice(arr):\n    if arr.ndim == 3:\n        return arr[:, :, arr.shape[2] // 2]\n    return arr\n\ninput_slice = get_middle_slice(input_img)\ngt_slice = get_middle_slice(gt_mask)\npred_slice = get_middle_slice(pred_mask)\n\n# === Plotting ===\nplt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nplt.imshow(input_slice, cmap='gray')\nplt.title(\"Input Image\")\nplt.axis(\"off\")\n\nplt.subplot(1,3,2)\nplt.imshow(gt_slice, cmap='jet')\nplt.title(\"Ground Truth Mask\")\nplt.axis(\"off\")\n\nplt.subplot(1,3,3)\nplt.imshow(pred_slice, cmap='jet')\nplt.title(\"Predicted Mask\")\nplt.axis(\"off\")\n\nplt.suptitle(f\"{instance_file} - Input | Ground Truth | Prediction\")\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}