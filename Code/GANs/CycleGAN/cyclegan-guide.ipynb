{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prepare the data and their labels for the CycleGan\n## The data format required is pngs\n## The following code assumes the original data format is npys","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\nimport numpy as np\nfrom PIL import Image\n\n# === Utility Function ===\ndef normalize_img(arr):\n    arr = arr.astype(np.float32)\n    arr = (arr - arr.min()) / (arr.max() - arr.min() + 1e-8)\n    return (arr * 255).astype(np.uint8)\n\n# === User Input Required: Define Dataset Paths ===\n# Please update these paths to point to your own dataset locations\n\n# Module A (e.g., ACDC)\nmodule_a_images_path = \"/path/to/module_a/images\"  # e.g., npy images\nmodule_a_masks_path = \"/path/to/module_a/masks\"    # e.g., corresponding masks\n\n# Module B (e.g., EMIDEC)\nmodule_b_images_path = \"/path/to/module_b/images\"  # e.g., npy images\nmodule_b_masks_path = \"/path/to/module_b/masks\"    # e.g., corresponding masks\n\n# Output Directory (default: working directory)\noutput_root = \"/path/to/output/directory\"  # e.g., ./cyclegan_data\n\n# === Output Subdirectories (automatically created) ===\ntrainA_path = os.path.join(output_root, \"trainA\")\ntrainB_path = os.path.join(output_root, \"trainB\")\nmodule_a_masks_output = os.path.join(output_root, \"module_a/masks\")\nmodule_b_masks_output = os.path.join(output_root, \"module_b/masks\")\n\nos.makedirs(trainA_path, exist_ok=True)\nos.makedirs(trainB_path, exist_ok=True)\nos.makedirs(module_a_masks_output, exist_ok=True)\nos.makedirs(module_b_masks_output, exist_ok=True)\n\n# === Process Module A ===\na_count = 0\nfor idx, file in enumerate(sorted(os.listdir(module_a_images_path))):\n    if not file.endswith(\".npy\"):\n        continue\n\n    arr = np.load(os.path.join(module_a_images_path, file))\n    norm_arr = normalize_img(arr)\n    img = Image.fromarray(norm_arr)\n\n    output_filename = f\"{idx:04d}.png\"\n    img.save(os.path.join(trainA_path, output_filename))\n\n    # Adjust based on your naming convention\n    ending = file.replace(\"merged_\", \"\")\n    mask_name = f\"custom_image_{ending}\"\n    mask_path = os.path.join(module_a_masks_path, mask_name)\n\n    mask = np.load(mask_path)\n    mask_output_filename = f\"{idx:04d}.npy\"\n    np.save(os.path.join(module_a_masks_output, mask_output_filename), mask)\n\n    a_count += 1\n\nprint(f\"Total images saved in trainA (Module A): {a_count}\")\nprint(f\"Total masks saved in module_a/masks (Module A): {a_count}\")\n\n# === Process Module B ===\nb_count = 0\nfor idx, file in enumerate(sorted(os.listdir(module_b_images_path))):\n    if not file.endswith(\".npy\"):\n        continue\n\n    arr = np.load(os.path.join(module_b_images_path, file))\n    norm_arr = normalize_img(arr)\n    img = Image.fromarray(norm_arr)\n\n    output_filename = f\"{idx:04d}.png\"\n    img.save(os.path.join(trainB_path, output_filename))\n\n    mask_filename = file\n    mask_path = os.path.join(module_b_masks_path, mask_filename)\n    mask = np.load(mask_path)\n\n    mask_output_filename = f\"{idx:04d}.npy\"\n    np.save(os.path.join(module_b_masks_output, mask_output_filename), mask)\n\n    b_count += 1\n\nprint(f\"Total images saved in trainB (Module B): {b_count}\")\nprint(f\"Total masks saved in module_b/masks (Module B): {b_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Augment and upsample module B (emidec) >>> images and masks","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\nfrom PIL import Image, ImageOps\n\n# === User Input Required: Define Dataset Path ===\n# Please update this path to your own trainB directory\ntrainB_path = \"/path/to/trainB\"  # e.g., \"./cyclegan_data/trainB\"\n\n# === Horizontal and Vertical Flipping Augmentation ===\n\n# List original image files\nimage_files = sorted(os.listdir(trainB_path))\noriginal_count = len(image_files)\n\naugmented_count = 0\nfor file in image_files:\n    img_path = os.path.join(trainB_path, file)\n    img = Image.open(img_path)\n\n    # Horizontal flip\n    img_h = ImageOps.mirror(img)\n    img_h.save(os.path.join(trainB_path, f\"{file[:-4]}_h.png\"))\n    augmented_count += 1\n\n    # Vertical flip\n    img_v = ImageOps.flip(img)\n    img_v.save(os.path.join(trainB_path, f\"{file[:-4]}_v.png\"))\n    augmented_count += 1\n\nprint(f\"Performed horizontal and vertical flips on {original_count} images, generating {augmented_count} augmented images.\")\n\n# === Rotation-Based Augmentation to Reach Target Count ===\n\n# Settings\n# Please set your desired target count below\ntarget_count = 2154  # e.g., desired number of images after augmentation\nrotation_angles = [90, 180, 270, 45, 135, 30, 60]  # angles for rotation augmentation\n\n# Get updated list of images after flips\nimage_files = sorted(os.listdir(trainB_path))\ncurrent_count = len(image_files)\naugment_index = 0\n\nprint(f\"Starting rotation augmentation with {current_count} images...\")\n\nwhile current_count < target_count:\n    file = image_files[augment_index % len(image_files)]\n    img_path = os.path.join(trainB_path, file)\n    img = Image.open(img_path)\n\n    for angle in rotation_angles:\n        if current_count >= target_count:\n            break\n        rotated = img.rotate(angle)\n        new_filename = f\"{file[:-4]}_r{angle}_{augment_index}.png\"\n        rotated.save(os.path.join(trainB_path, new_filename))\n        current_count += 1\n\n    augment_index += 1\n\nprint(f\"Rotation augmentation completed. Final total images: {current_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# === Imports ===\nimport os\nimport numpy as np\n\n# === User Input Required: Define Paths ===\n# Please update these paths to your dataset directories\n\n# Directory containing trainB images\ntrainB_path = \"/path/to/trainB\"  # e.g., \"./cyclegan_data/trainB\"\n\n# Directory containing masks corresponding to trainB images\nmasks_path = \"/path/to/module_b/masks\"  # e.g., \"./module_b/masks\"\n\n# === Settings ===\n# Desired total number of images/masks after augmentation\ntarget_count = 2154  # set as per your dataset requirement\n\n# Rotation angles to apply for augmentation\nrotation_angles = [90, 180, 270, 45, 135, 30, 60]\n\n# === Get original mask filenames ===\nmask_files = sorted([f for f in os.listdir(masks_path) if f.endswith(\".npy\")])\ncurrent_count = len(os.listdir(trainB_path))  # image count for loop control\naugment_index = 0\n\nprint(f\"Starting with {len(mask_files)} masks to match {current_count} images...\")\n\n# === Horizontal & Vertical Flipping Augmentation ===\nfor mask_file in mask_files:\n    mask_path = os.path.join(masks_path, mask_file)\n    mask = np.load(mask_path)\n\n    # Flip horizontally\n    mask_h = np.fliplr(mask)\n    new_name_h = f\"{mask_file[:-4]}_h.npy\"\n    np.save(os.path.join(masks_path, new_name_h), mask_h)\n\n    # Flip vertically\n    mask_v = np.flipud(mask)\n    new_name_v = f\"{mask_file[:-4]}_v.npy\"\n    np.save(os.path.join(masks_path, new_name_v), mask_v)\n\nprint(\"Horizontal & vertical flips done.\")\n\n# === Rotation-Based Augmentation to Reach Target Count ===\n\n# Get updated list of mask files (original + flips)\nmask_files = sorted([f for f in os.listdir(masks_path) if f.endswith(\".npy\")])\ncurrent_image_count = len(os.listdir(trainB_path))\naugment_index = 0\n\nprint(f\"Starting rotations to reach {target_count} total images...\")\n\nwhile current_image_count < target_count:\n    mask_file = mask_files[augment_index % len(mask_files)]\n    mask_path = os.path.join(masks_path, mask_file)\n    mask = np.load(mask_path)\n\n    for angle in rotation_angles:\n        if current_image_count >= target_count:\n            break\n\n        # Rotate mask using np.rot90 for 90-degree multiples, else use scipy.ndimage.rotate\n        if angle in [90, 180, 270]:\n            k = angle // 90\n            rotated = np.rot90(mask, k)\n        else:\n            # For non-90 rotations, use scipy.ndimage.rotate with order=0 to preserve mask labels\n            from scipy.ndimage import rotate\n            rotated = rotate(mask, angle, reshape=False, order=0, mode='nearest')\n\n        new_name = f\"{mask_file[:-4]}_r{angle}_{augment_index}.npy\"\n        np.save(os.path.join(masks_path, new_name), rotated)\n\n        current_image_count += 1\n\n    augment_index += 1\n\nprint(f\"Done! Final mask count matches or exceeds trainB image count: {current_image_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Augment and replace A (ACDC) >>>images and masks","metadata":{}},{"cell_type":"code","source":"# === Imports ===\nimport os\nimport random\nimport numpy as np\nfrom PIL import Image, ImageOps\n\n# === User Input Required: Define Paths ===\n# Please update these paths to your dataset directories\n\n# Directory containing trainA images\ntrainA_path = \"/path/to/trainA\"  # e.g., \"./cyclegan_data/trainA\"\n\n# Directory containing masks corresponding to trainA images\nmasksA_path = \"/path/to/module_a/masks\"  # e.g., \"./module_a/masks\"\n\n# === Settings ===\nrotation_angles = [90, 180, 270, 45, 135, 30, 60]\naugmentation_choices = ['original', 'flip_h', 'flip_v', 'rotate']\n\n# === Get all .png files ===\nimage_files = sorted([f for f in os.listdir(trainA_path) if f.endswith('.png')])\n\nprint(f\"Original number of samples in trainA: {len(image_files)}\")\n\n# === Temp directories to save augmented data ===\ntemp_images = trainA_path + \"_temp\"\ntemp_masks = masksA_path + \"_temp\"\n\nos.makedirs(temp_images, exist_ok=True)\nos.makedirs(temp_masks, exist_ok=True)\n\n# === Process each pair ===\nfor idx, file in enumerate(image_files):\n    # Load image\n    img_path = os.path.join(trainA_path, file)\n    img = Image.open(img_path)\n\n    # Load matching mask (.npy)\n    mask_stem = file[:-4]  # remove .png extension\n    mask_path = os.path.join(masksA_path, f\"{mask_stem}.npy\")\n    mask = np.load(mask_path)\n\n    # Randomly choose augmentation type\n    choice = random.choice(augmentation_choices)\n\n    # === Apply augmentation to image ===\n    if choice == 'flip_h':\n        img_aug = ImageOps.mirror(img)\n    elif choice == 'flip_v':\n        img_aug = ImageOps.flip(img)\n    elif choice == 'rotate':\n        angle = random.choice(rotation_angles)\n        img_aug = img.rotate(angle)\n    else:\n        img_aug = img  # original (no augmentation)\n\n    # === Apply the same augmentation to mask ===\n    mask_aug = mask.copy()\n    if choice == 'flip_h':\n        mask_aug = np.fliplr(mask_aug)\n    elif choice == 'flip_v':\n        mask_aug = np.flipud(mask_aug)\n    elif choice == 'rotate':\n        if angle % 90 == 0:\n            k = angle // 90\n            mask_aug = np.rot90(mask_aug, k=k)\n        else:\n            # For non-90-degree angles, use PIL for rotation with nearest interpolation\n            mask_pil = Image.fromarray(mask_aug)\n            mask_pil = mask_pil.rotate(angle, resample=Image.NEAREST)\n            mask_aug = np.array(mask_pil)\n\n    # === Save augmented image and mask ===\n    img_aug.save(os.path.join(temp_images, f\"{mask_stem}.png\"))\n    np.save(os.path.join(temp_masks, f\"{mask_stem}.npy\"), mask_aug)\n\n# === Replace old folders with augmented data ===\nimport shutil\nshutil.rmtree(trainA_path)\nshutil.rmtree(masksA_path)\n\nos.rename(temp_images, trainA_path)\nos.rename(temp_masks, masksA_path)\n\nprint(f\"✅ Augmentation done & replaced: {len(image_files)} pairs\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndef count_files_in_folder(folder_path):\n    return sum(1 for entry in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, entry)))\n\n# Example usage\nfolder_path = # path\nfile_count = count_files_in_folder(folder_path)\nprint(f\"Number of files in '{folder_path}': {file_count}\")\n\nfolder_path = # path\nfile_count = count_files_in_folder(folder_path)\nprint(f\"Number of files in '{folder_path}': {file_count}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Install CycleGan and apply cutsom weighted loss by applying masks as weights","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix\n%cd pytorch-CycleGAN-and-pix2pix\n!pip install -r requirements.txt\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Path to the file you want to overwrite\n#example\nfile_path = \"...../pytorch-CycleGAN-and-pix2pix/models/cycle_gan_model.py\"\n\n# Your new content as a single multiline string (replace this with your actual content)\nnew_content = \"\"\"\n# Put your full new file content here\nimport os\nimport numpy as np\nimport torch\nimport itertools\nfrom util.image_pool import ImagePool\nfrom .base_model import BaseModel\nfrom . import networks\n\n\nclass CycleGANModel(BaseModel):\n    @staticmethod\n    def modify_commandline_options(parser, is_train=True):\n        parser.set_defaults(no_dropout=True)\n        if is_train:\n            parser.add_argument('--lambda_A', type=float, default=10.0)\n            parser.add_argument('--lambda_B', type=float, default=10.0)\n            parser.add_argument('--lambda_identity', type=float, default=0.5)\n        return parser\n\n    def __init__(self, opt):\n        BaseModel.__init__(self, opt)\n        self.loss_names = ['D_A', 'G_A', 'cycle_A', 'idt_A',\n                           'D_B', 'G_B', 'cycle_B', 'idt_B']\n        visual_names_A = ['real_A', 'fake_B', 'rec_A']\n        visual_names_B = ['real_B', 'fake_A', 'rec_B']\n        if self.isTrain and self.opt.lambda_identity > 0.0:\n            visual_names_A.append('idt_B')\n            visual_names_B.append('idt_A')\n        self.visual_names = visual_names_A + visual_names_B\n\n        if self.isTrain:\n            self.model_names = ['G_A', 'G_B', 'D_A', 'D_B']\n        else:\n            self.model_names = ['G_A', 'G_B']\n\n        self.netG_A = networks.define_G(opt.input_nc, opt.output_nc, opt.ngf,\n                                        opt.netG, opt.norm, not opt.no_dropout,\n                                        opt.init_type, opt.init_gain, self.gpu_ids)\n        self.netG_B = networks.define_G(opt.output_nc, opt.input_nc, opt.ngf,\n                                        opt.netG, opt.norm, not opt.no_dropout,\n                                        opt.init_type, opt.init_gain, self.gpu_ids)\n\n        if self.isTrain:\n            self.netD_A = networks.define_D(opt.output_nc, opt.ndf, opt.netD,\n                                            opt.n_layers_D, opt.norm,\n                                            opt.init_type, opt.init_gain, self.gpu_ids)\n            self.netD_B = networks.define_D(opt.input_nc, opt.ndf, opt.netD,\n                                            opt.n_layers_D, opt.norm,\n                                            opt.init_type, opt.init_gain, self.gpu_ids)\n\n            if opt.lambda_identity > 0.0:\n                assert (opt.input_nc == opt.output_nc)\n\n            self.fake_A_pool = ImagePool(opt.pool_size)\n            self.fake_B_pool = ImagePool(opt.pool_size)\n\n            self.criterionGAN = networks.GANLoss(opt.gan_mode).to(self.device)\n            self.criterionCycle = torch.nn.L1Loss()\n            self.criterionIdt = torch.nn.L1Loss()\n\n            self.optimizer_G = torch.optim.Adam(\n                itertools.chain(self.netG_A.parameters(), self.netG_B.parameters()),\n                lr=opt.lr, betas=(opt.beta1, 0.999)\n            )\n            self.optimizer_D = torch.optim.Adam(\n                itertools.chain(self.netD_A.parameters(), self.netD_B.parameters()),\n                lr=opt.lr, betas=(opt.beta1, 0.999)\n            )\n            self.optimizers.append(self.optimizer_G)\n            self.optimizers.append(self.optimizer_D)\n\n    def weighted_cycle_loss(self, pred, target, mask=None):\n        \n        loss = torch.abs(pred - target)\n        if mask is not None:\n            mask = mask.to(loss.device).float()\n            loss = loss * mask\n        return loss.mean()\n\n    def set_input(self, input):\n        AtoB = self.opt.direction == 'AtoB'\n        self.real_A = input['A' if AtoB else 'B'].to(self.device)\n        self.real_B = input['B' if AtoB else 'A'].to(self.device)\n        self.image_paths = input['A_paths' if AtoB else 'B_paths']\n\n        if AtoB:\n            # Load Module A mask\n            mask_dir = \"/kaggle/working/module_a/masks\"\n            masks = []\n            for path in self.image_paths:\n                filename = os.path.basename(path)\n                filename_stem = os.path.splitext(filename)[0]\n                mask_path = os.path.join(mask_dir, f\"{filename_stem}.npy\")\n                if os.path.exists(mask_path):\n                    mask = np.load(mask_path)\n                else:\n                    # fallback: all ones means no weighting\n                    mask = np.ones_like(self.real_A[0].cpu().numpy()[0])\n                mask_tensor = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float()\n                masks.append(mask_tensor)\n            self.real_A_mask = torch.cat(masks, dim=0).to(self.device)\n            self.real_B_mask = None\n        else:\n            # Load Module B mask\n            mask_dir = \"/kaggle/working/module_b/masks\"\n            masks = []\n            for path in self.image_paths:\n                filename = os.path.basename(path)\n                filename_stem = os.path.splitext(filename)[0]\n                mask_path = os.path.join(mask_dir, f\"{filename_stem}.npy\")\n                if os.path.exists(mask_path):\n                    mask = np.load(mask_path)\n                else:\n                    mask = np.ones_like(self.real_B[0].cpu().numpy()[0])\n                mask_tensor = torch.from_numpy(mask).unsqueeze(0).unsqueeze(0).float()\n                masks.append(mask_tensor)\n            self.real_B_mask = torch.cat(masks, dim=0).to(self.device)\n            self.real_A_mask = None\n\n    def forward(self):\n       \n        self.fake_B = self.netG_A(self.real_A)\n        self.rec_A = self.netG_B(self.fake_B)\n        self.fake_A = self.netG_B(self.real_B)\n        self.rec_B = self.netG_A(self.fake_A)\n\n    def backward_D_basic(self, netD, real, fake):\n   \n        pred_real = netD(real)\n        loss_D_real = self.criterionGAN(pred_real, True)\n        pred_fake = netD(fake.detach())\n        loss_D_fake = self.criterionGAN(pred_fake, False)\n        loss_D = (loss_D_real + loss_D_fake) * 0.5\n        loss_D.backward()\n        return loss_D\n\n    def backward_D_A(self):\n        fake_B = self.fake_B_pool.query(self.fake_B)\n        self.loss_D_A = self.backward_D_basic(self.netD_A, self.real_B, fake_B)\n\n    def backward_D_B(self):\n        fake_A = self.fake_A_pool.query(self.fake_A)\n        self.loss_D_B = self.backward_D_basic(self.netD_B, self.real_A, fake_A)\n\n    def backward_G(self):\n        lambda_idt = self.opt.lambda_identity\n        lambda_A = self.opt.lambda_A\n        lambda_B = self.opt.lambda_B\n\n        if lambda_idt > 0:\n            self.idt_A = self.netG_A(self.real_B)\n            self.loss_idt_A = self.criterionIdt(self.idt_A, self.real_B) * lambda_B * lambda_idt\n            self.idt_B = self.netG_B(self.real_A)\n            self.loss_idt_B = self.criterionIdt(self.idt_B, self.real_A) * lambda_A * lambda_idt\n        else:\n            self.loss_idt_A = 0\n            self.loss_idt_B = 0\n\n        self.loss_G_A = self.criterionGAN(self.netD_A(self.fake_B), True)\n        self.loss_G_B = self.criterionGAN(self.netD_B(self.fake_A), True)\n\n        # Mask-weighted cycle losses\n        self.loss_cycle_A = self.weighted_cycle_loss(self.rec_A, self.real_A, self.real_A_mask) * lambda_A\n        self.loss_cycle_B = self.weighted_cycle_loss(self.rec_B, self.real_B, self.real_B_mask) * lambda_B\n\n        self.loss_G = self.loss_G_A + self.loss_G_B + \\\n                      self.loss_cycle_A + self.loss_cycle_B + \\\n                      self.loss_idt_A + self.loss_idt_B\n        self.loss_G.backward()\n\n    def optimize_parameters(self):\n        self.forward()\n        self.set_requires_grad([self.netD_A, self.netD_B], False)\n        self.optimizer_G.zero_grad()\n        self.backward_G()\n        self.optimizer_G.step()\n\n        self.set_requires_grad([self.netD_A, self.netD_B], True)\n        self.optimizer_D.zero_grad()\n        self.backward_D_A()\n        self.backward_D_B()\n        self.optimizer_D.step()\n\n# ... rest of your new code ...\n\"\"\"\n\n# Overwrite the file with new content\nwith open(file_path, \"w\") as f:\n    f.write(new_content)\n\nprint(f\"✅ Successfully overwritten the file: {file_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"!python /kaggle/working/pytorch-CycleGAN-and-pix2pix/train.py \\  ##replace with the path for ypu train.py\n  --dataroot /kaggle/working/cyclegan_data \\   ##replace with the path for your prepared data root\n  --name emidec2acdc \\\n  --model cycle_gan \\\n  --gpu_ids 0 \\\n  --input_nc 1 --output_nc 1 \\\n  --preprocess scale_width_and_crop \\\n  --crop_size 128 \\\n  --load_size 128 \\\n  --batch_size 4\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference and visualise predictions","metadata":{}},{"cell_type":"code","source":"!python test.py \\   ##replace with the path for ypu test.py\n  --dataroot /kaggle/working/cyclegan_data \\  ##replace with the path for your prepared data root\n  --name emidec2acdc \\\n  --model cycle_gan \\\n  --direction AtoB \\\n  --input_nc 1 --output_nc 1 \\\n  --preprocess scale_width_and_crop \\\n  --load_size 128 --crop_size 128 \\   \n  --num_test 999999  ## replace with the number of samples needed (default 50)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport matplotlib.pyplot as plt\nfrom PIL import Image\n\n# Path to test results\nresults_path = './results/emidec2acdc/test_latest/images'  ## replace with the actual path\n\n# Get all translated image names (ending with _fake_B.png)\nfake_images = sorted([f for f in os.listdir(results_path) if f.endswith('_fake_B.png')])\n\n# Display a few\nnum_examples = 150\nplt.figure(figsize=(15, num_examples * 3))\n\nfor i, fake_name in enumerate(fake_images[:num_examples]):\n    real_name = fake_name.replace('fake_B', 'real_A')\n\n    real_img = Image.open(os.path.join(results_path, real_name)).convert('L')\n    fake_img = Image.open(os.path.join(results_path, fake_name)).convert('L')\n\n    # Real\n    plt.subplot(num_examples, 2, 2*i+1)\n    plt.imshow(real_img, cmap='gray')\n    plt.title(f'Real A: {real_name}')\n    plt.axis('off')\n\n    # Fake\n    plt.subplot(num_examples, 2, 2*i+2)\n    plt.imshow(fake_img, cmap='gray')\n    plt.title(f'Fake B: {fake_name}')\n    plt.axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}